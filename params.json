{"name":"woj1208 Sherlock's Code","tagline":"woj1208解题报告","body":"# 题目链接\r\n<br>[woj1208 Sherlock's Code](http://acm.whu.edu.cn/learn/problem/detail?problem_id=1208)\r\n<br>题目的大概意思就是输入两个长度为N的数组，计算数组的两两之和，得到N^2个数后，从小到大排序，输出前N个数。\r\n# 数据规模\r\n数组的长度1 <= N <= 50000；空间限制：65536KB；时间限制是1s.\r\n# 解题思路\r\n<br>拿到题的第一想法就是，肯定不能直接按照题目的意思去做，因为这样做内存很容易超。需要另辟思路，第一个想法是用一个规模为N的堆(大根堆)去维护输出的结果。遍历计算，每次得到一个和值，就与堆顶的元素相比较，如果该和值比堆顶元素小，就将堆顶元素出堆，将该元素入堆，重新调整堆。当所有元素遍历完以后，再对这个大根堆进行一次排序，然后输出即可。代码如下：\r\n```\r\n    \r\n#include<iostream>\r\n#include<stdio.h>\r\n#include<algorithm>\r\n#include<vector>\r\nusing namespace std;\r\nint main()\r\n{\r\n\tfreopen(\"in.txt\",\"r\",stdin);\r\n\tint n;\r\n\twhile(cin>>n)\r\n\t{\r\n\t\tvector<int> va,vb,vheap;\r\n\t\tint temp;\r\n\t\tfor(int i=0;i<n;++i)\r\n\t\t{\r\n\t\t\tcin>>temp;\r\n\t\t\tva.push_back(temp);\r\n\t\t}\r\n\t\tfor(int i=0;i<n;++i)\r\n\t\t{\r\n\t\t\tcin>>temp;\r\n\t\t\tvb.push_back(temp);\r\n\t\t}\r\n\r\n\t\tfor(int i=0;i<n;++i)//初始化堆 \r\n\t\t{\r\n\t\t\ttemp=va[0]+vb[i];\r\n\t\t\tvheap.push_back(temp);\r\n\t\t}\r\n\t\tmake_heap(vheap.begin(),vheap.end()); \r\n\t\t\r\n\t\tfor(int i=1;i<n;++i)\r\n\t\t{\r\n\t\t\tfor(int j=0;j<n;++j)\r\n\t\t\t{\r\n\t\t\t\tint temp=va[i]+vb[j];\r\n\t\t\t\tif(temp<vheap[0])//小于堆顶元素则重新调整堆\r\n\t\t\t\t{\r\n\t\t\t\t\tvheap.erase(vheap.begin());//删除堆顶元素\r\n\t\t\t\t\tvheap.push_back(temp);//temp入堆\r\n\t\t\t\t\tmake_heap(vheap.begin(),vheap.end());\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tsort_heap(vheap.begin(),vheap.end());\r\n\t\tcout<<vheap[0];\r\n\t\tfor(int i=1;i<n;++i)\r\n\t\t\tcout<<\" \"<<vheap[i];\r\n\t\tcout<<endl;\r\n\t\tva.clear();\r\n\t\tvb.clear();\r\n\t\tvheap.clear();\r\n\t}\r\n\treturn 0;\r\n}\r\n```\r\n<br>上面的算法复杂度还是比较高的，O(n^2log n)，提交超时也正常。还是沿着这种思路，稍微优化修改一下就行了。上面的代码比较粗糙。\r\n<br>这题的优化解法可以参考《算法导论》中k路归并算法，可以这样考虑，将a[n]和b[n]排序后，用b[n]中的每个元素去加a[n]中的一个元素，得到n个有序表，再把这n个有序表合并成一个有序表即可。\r\n<br>得到的n个有序表如下：\r\n<br>a[0]+b[0]<= a[0]+b[1]<= a[0]+b[2]<=…<= a[0]+b[n-1];\r\n<br>a[1]+b[0]<= a[1]+b[1]<= a[1]+b[2]<=…<= a[1]+b[n-1];\r\n<br>…\r\n<br>a[n-1]+b[0]<= a[n-1]+b[1]<= a[n-1]+b[2]<=…<= a[n-1]+b[n-1].\r\n<br>归并时，可以这样考虑，每个表的元素按序移入一个新表中，把每个表的当前元素放入一个二叉堆中，每次删除最小值并放入新表中，然后加入此序列的下一个元素，直到n个表遍历完。这种算法每次耗时log(n)，n次共耗时nlog(n)，所以AC掉这题是没有问题的。\r\n<br>具体的实现就是：读入a[n]和b[n]，并将其升序排序，再将第一个有序表a[0] + b[i] ( 0<=i<=n-1)读入q向量中，维护一个大小为n的二叉堆。然后考虑第1个有序表，b[1] + a[i] (0<=i<=n-1)，如果b[1] + a[i]比堆q的堆顶元素大，则退出，否则删除堆的堆顶元素，插入data2[1] + data1[i]，依次计算其他有序表即可。再q的数据拷贝到a中，并对a按升序排序，输出a中的数据即可。\r\n<br>最终的AC代码如下：\r\n```    \r\n#include <iostream>\r\n#include <stdio.h>\r\n#include <queue>\r\n#include <algorithm>\r\nusing namespace std;  \r\nconst int N=50000;\r\nint main()  \r\n{\r\n    freopen(\"in.txt\",\"r\",stdin);\r\n    int n;\r\n    int num1[N];\r\n    int num2[N];\r\n    priority_queue<int,deque<int>,less<int> > big;\r\n    while(scanf(\"%d\",&n)!=EOF)\r\n    { \r\n        for(int i=0;i<n;i++)  \r\n        \tscanf(\"%d\",&num1[i]);  \r\n        sort(num1,num1+n);\r\n        for(int j=0;j<n;j++)  \r\n        {  \r\n            scanf(\"%d\",&num2[j]);  \r\n            big.push(num1[0]+num2[j]);  \r\n        }  \r\n        sort(num2,num2+n);  \r\n        for(int k=1;k<n;k++) \r\n            for(int l=0;l<n;l++)  \r\n            {  \r\n                if(num1[k]+num2[l]>big.top())  \r\n                    break;  \r\n                    big.pop();  \r\n                    big.push(num1[k]+num2[l]);  \r\n            } \r\n        for(int k=0;k<n;k++)  \r\n        {  \r\n            num1[n-k-1]=big.top();  \r\n            big.pop();  \r\n        }\r\n        printf(\"%d\",num1[0]);  \r\n        for(int i=1;i<n;i++)  \r\n        \tprintf(\" %d\",num1[i]);\r\n\t\t//printf(\"\\n\");\r\n    }\r\n    return 0;\r\n}\r\n```\r\n<br>更多请参考[我的CSDN博客](http://blog.csdn.net/u011000290)\r\n","google":"bat001","note":"Don't delete this file! It's used internally to help with page regeneration."}